<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link href="main.css" rel="stylesheet" media="all">
<meta name="description" content="Learning to Segment Breast Biopsy Whole Slide Images" />
<meta name="keywords" content="cnn, semantic segmentation, wsi, breast cancer">
<script>
function buttonSwitch(id, text)
{
	old_src = document.getElementById(id).src;
	ind = old_src.lastIndexOf('/');
	document.getElementById(id).src = old_src.substr(0,ind+1) + text;
}

</script>
<title>Y-Net</title>
</head>

<body>

<div id="top_arrow" style="position: fixed; bottom: 10px; right: 10px;">
<a href="#title">
<img src="webfigures/top_arrow.jpg" style="border: 0pt none ; width: 26px; height: 32px;"/></a>
</div>

<h2 id="title" class="auto-style1">Y-Net: Joint Segmentation and Classification for Diagnosis of Breast Biopsy Images</h2>

<p class="auto-style7"  align="center">
	<a href="https://sachinmehtangb.wixsite.com/sachinmehta" target="_blank">Sachin Mehta</a><sup>*,1</sup>, <a href="" target="_blank">Ezgi Mercan</a><sup>*,1</sup>, 
   <a href="" target="_blank">Jamen Bartlett</a><sup>2</sup>, <a href="" target="_blank">Donald Weaver</a><sup>2</sup>, <a href="" target="_blank">Joann Elmore</a><sup>1</sup>, and <a href="https://homes.cs.washington.edu/~shapiro/" target="_blank">Linda Shapiro</a><sup>1</sup>
</p>

<p class="auto-style7"  align="center">
<sup>1</sup>
<a href="https://www.washington.edu/", target="_blank">University of Washington, Seattle, WA, USA</a>
<br>
<sup>2</sup>
<a href="http://www.med.uvm.edu/", target="_blank">University of Vermont, Burlington, VT, USA</a>
</p>
<!--<p class="auto-style7"  align="center">&nbsp;&nbsp;&nbsp; </p>-->
<p align=left>&nbsp;</p>
<p align="center">
<table style="width:960px" align="center">
<tr>
	<td><img width=960px alt="" src="webfigures/overview.png"></td>	
</tr>
<tr>
	<td><p align="justify"><b>Figure:</b> Overview of our method for detecting breast cancer. Our system is given an ROI from a breast biopsy WSI and breaks it into instances that are fed into Y-Net. Y-Net produces two different outputs: an instance-level segmentation mask and an instance-level probability map. The instance-level segmentation masks have, for each instance, the predicted labels of the eight different tissue types. These are combined to produce a segmentation mask for the whole ROI. The instance-level probability map contains (for every pixel) the maximum value of the probability of that instance being in one of the four diagnostic categories. This map is thresholded to binary and combined with the segmentation mask to produce the discriminative segmentation mask. A multi-layer perceptron then uses the frequency and co-occurrence features extracted from the final mask to predict the cancer diagnosis.</p></td>
</tr>
</table>

<p class="style2"><strong><span class="auto-style6">Abstract</span></strong></p>
<p class="auto-style5">In this paper, we introduce a conceptually simple network for generating discriminative tissue-level segmentation masks for the purpose of breast cancer diagnosis. Our method efficiently segments different types of tissues in breast biopsy images while simultaneously predicting a discriminative map for identifying important areas in an image. Our network, Y-Net, extends and generalizes U-Net by adding a parallel branch for discriminative map generation and by supporting convolutional block modularity, which allows the user to adjust network efficiency without altering the network topology. Y-Net delivers state-of-the-art segmentation accuracy while learning 6.6x fewer parameters than its closest competitors. The addition of descriptive power from Y-Net's discriminative segmentation masks improve diagnostic classification accuracy by 7% over state-of-the-art methods for diagnostic classification.
</p>

<p class="auto-style5">&nbsp;</p>
<p id="downloads", class="auto-style4"><strong>Downloads</strong></p>
<table cellSpacing=4 cellPadding=2 border=0 style="width: 90%">
<tr COLSPAN="2">
	<td align="center" valign="center">
		<img style="padding:0; clear:both; " src="webfigures/results.gif" align="middle" alt="Snapshot for paper" class="pdf" width="200" />
	</td>
	<td>
	</td>
	<td align="left" class="auto-style5"><i>Learning to Segment Breast Biopsy Whole Slide Images</i>
	<br>
	Sachin Mehta<sup>*</sup>, Ezgi Mercan<sup>*</sup>, Jamen Bartlett, Donald Weaver, Joann Elmore, and Linda Shapiro
	<br>
	<em>21st International Conference On Medical Image Computing & Computer Assisted Intervention (MICCAI'18)</em> 
	<br>
	<img alt="" height="32" src="webfigures/pdf.jpg" width="31">&nbsp;&nbsp;[<a target="_blank" href="">Paper</a>]<br><br>
	<img alt="" height="32" src="webfigures/github.jpg" width="31">&nbsp;&nbsp;[<a target="_blank" href="https://github.com/sacmehta/YNet">Source Code</a>]<br><br>
	</td>
	</tr>
</table>
<br>

<p class="auto-style5">&nbsp;</p>
<p id="performance", class="auto-style4"><strong>Results</strong></p>
<table style="width:960px" align="center">
<tr>
	<td><img width=800px alt="" src="webfigures/resultsSeg.png"></td>
</tr>
<tr>
	<td><img width=800px alt="" src="webfigures/resultsClass.png"></td>
</tr>
<tr>
	<td colspan=2><p class="auto-style5"><b>Figure:</b> Quantitative comparison of different methods on the Breast Biopsy dataset.</p></td>
</tr>
</table>

<p class="auto-style1"><font color="#999999">This page is adapted from PSPNet.</font></p>

</body>

</html>
